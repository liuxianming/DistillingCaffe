<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>Caffe: include/caffe/vision_layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_4b7f3da7c7b4301d805dae0326fb91b7.html">caffe</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">vision_layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;caffe/blob.hpp&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;caffe/common.hpp&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;caffe/common_layers.hpp&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;caffe/data_layers.hpp&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;caffe/layer.hpp&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;caffe/loss_layers.hpp&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;caffe/neuron_layers.hpp&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;caffe/proto/caffe.pb.h&quot;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacecaffe.html">caffe</a> {</div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00024"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html">   24</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a35c6389878e77ab0a4a479e5441563cc">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#ac330e2fb166bca496edd277b0495f6eb">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div>
<div class="line"><a name="l00033"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">   33</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">MinBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00034"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">   34</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00035"></a><span class="lineno"><a class="line" href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">   35</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">EqualNumBottomTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  <span class="comment">// Helper functions that abstract away the column buffer and gemm arguments.</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  <span class="comment">// The last argument in forward_cpu_gemm is so that we can skip the im2col if</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  <span class="comment">// we just called weight_cpu_gemm with the same input.</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;  <span class="keywordtype">void</span> forward_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;      Dtype* output, <span class="keywordtype">bool</span> skip_im2col = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;  <span class="keywordtype">void</span> forward_cpu_bias(Dtype* output, <span class="keyword">const</span> Dtype* bias);</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;  <span class="keywordtype">void</span> backward_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;      Dtype* output);</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  <span class="keywordtype">void</span> weight_cpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* output, Dtype*</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;      weights);</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;  <span class="keywordtype">void</span> backward_cpu_bias(Dtype* bias, <span class="keyword">const</span> Dtype* input);</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="preprocessor">#ifndef CPU_ONLY</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;  <span class="keywordtype">void</span> forward_gpu_gemm(<span class="keyword">const</span> Dtype* col_input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;      Dtype* output, <span class="keywordtype">bool</span> skip_im2col = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;  <span class="keywordtype">void</span> forward_gpu_bias(Dtype* output, <span class="keyword">const</span> Dtype* bias);</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;  <span class="keywordtype">void</span> backward_gpu_gemm(<span class="keyword">const</span> Dtype* input, <span class="keyword">const</span> Dtype* weights,</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;      Dtype* col_output);</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <span class="keywordtype">void</span> weight_gpu_gemm(<span class="keyword">const</span> Dtype* col_input, <span class="keyword">const</span> Dtype* output, Dtype*</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;      weights);</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  <span class="keywordtype">void</span> backward_gpu_bias(Dtype* bias, <span class="keyword">const</span> Dtype* input);</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;  <span class="comment">// reverse_dimensions should return true iff we are implementing deconv, so</span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;  <span class="comment">// that conv helpers know which dimensions are which.</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">bool</span> reverse_dimensions() = 0;</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;  <span class="comment">// Compute height_out_ and width_out_ from other parameters.</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape() = 0;</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;  <span class="keywordtype">int</span> stride_h_, stride_w_;</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;  <span class="keywordtype">int</span> height_, width_;</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;  <span class="keywordtype">int</span> group_;</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;  <span class="keywordtype">int</span> num_output_;</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;  <span class="keywordtype">int</span> height_out_, width_out_;</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;  <span class="keywordtype">bool</span> bias_term_;</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;  <span class="keywordtype">bool</span> is_1x1_;</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160; <span class="keyword">private</span>:</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  <span class="comment">// wrap im2col/col2im so we don&#39;t have to remember the (long) argument lists</span></div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_im2col_cpu(<span class="keyword">const</span> Dtype* data, Dtype* col_buff) {</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    im2col_cpu(data, conv_in_channels_, conv_in_height_, conv_in_width_,</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        kernel_h_, kernel_w_, pad_h_, pad_w_, stride_h_, stride_w_, col_buff);</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  }</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_col2im_cpu(<span class="keyword">const</span> Dtype* col_buff, Dtype* data) {</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    col2im_cpu(col_buff, conv_in_channels_, conv_in_height_, conv_in_width_,</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;        kernel_h_, kernel_w_, pad_h_, pad_w_, stride_h_, stride_w_, data);</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;  }</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="preprocessor">#ifndef CPU_ONLY</span></div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_im2col_gpu(<span class="keyword">const</span> Dtype* data, Dtype* col_buff) {</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    im2col_gpu(data, conv_in_channels_, conv_in_height_, conv_in_width_,</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;        kernel_h_, kernel_w_, pad_h_, pad_w_, stride_h_, stride_w_, col_buff);</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;  }</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;  <span class="keyword">inline</span> <span class="keywordtype">void</span> conv_col2im_gpu(<span class="keyword">const</span> Dtype* col_buff, Dtype* data) {</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    col2im_gpu(col_buff, conv_in_channels_, conv_in_height_, conv_in_width_,</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        kernel_h_, kernel_w_, pad_h_, pad_w_, stride_h_, stride_w_, data);</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  }</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;  <span class="keywordtype">int</span> conv_out_channels_;</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  <span class="keywordtype">int</span> conv_in_channels_;</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  <span class="keywordtype">int</span> conv_out_spatial_dim_;</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  <span class="keywordtype">int</span> conv_in_height_;</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  <span class="keywordtype">int</span> conv_in_width_;</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;  <span class="keywordtype">int</span> kernel_dim_;</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;  <span class="keywordtype">int</span> weight_offset_;</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;  <span class="keywordtype">int</span> col_offset_;</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;  <span class="keywordtype">int</span> output_offset_;</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;  Blob&lt;Dtype&gt; col_buffer_;</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;  Blob&lt;Dtype&gt; bias_multiplier_;</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;};</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00131"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html">  131</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1ConvolutionLayer.html">ConvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">  161</a></span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">ConvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;      : <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div>
<div class="line"><a name="l00164"></a><span class="lineno"><a class="line" href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">  164</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Convolution&quot;</span>; }</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#a8505044adc26d89aae3055022898c9ea">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ace239a41953c9207efd1a9966570825c">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#ac1591049f064bd88ccdc785a948ed4b2">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1ConvolutionLayer.html#a4de7682afbd816037aba5da3ec66a9bb">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> reverse_dimensions() { <span class="keywordflow">return</span> <span class="keyword">false</span>; }</div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape();</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;};</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="classcaffe_1_1DeconvolutionLayer.html">  194</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1DeconvolutionLayer.html">DeconvolutionLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html">DeconvolutionLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;      : <a class="code" href="classcaffe_1_1BaseConvolutionLayer.html">BaseConvolutionLayer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;</div>
<div class="line"><a name="l00199"></a><span class="lineno"><a class="line" href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">  199</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Deconvolution&quot;</span>; }</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a3716cda5f7d7e81f7d19cf4313d2bfc5">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a49c3360133291f7e6593db36ec392d07">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a081ed64d7b91d42f9f441f849db2a58d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1DeconvolutionLayer.html#a2b4a2203001e8b5a5839955879551048">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">bool</span> reverse_dimensions() { <span class="keywordflow">return</span> <span class="keyword">true</span>; }</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> compute_output_shape();</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;};</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment"> * @brief cuDNN implementation of ConvolutionLayer.</span></div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment"> *        Fallback to ConvolutionLayer for CPU mode.</span></div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="comment"> * cuDNN accelerates convolution through forward kernels for filtering and bias</span></div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment"> * plus backward kernels for the gradient w.r.t. the filters, biases, and</span></div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment"> * inputs. Caffe + cuDNN further speeds up the computation through forward</span></div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment"> * parallelism across groups and backward parallelism across gradients.</span></div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="comment"> * The CUDNN engine does not have memory overhead for matrix buffers. For many</span></div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="comment"> * input and filter regimes the CUDNN engine is faster than the CAFFE engine,</span></div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="comment"> * but for fully-convolutional models and large inputs the CAFFE engine can be</span></div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment"> * faster as long as it fits in memory.</span></div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="comment">*/</span></div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="keyword">class </span>CuDNNConvolutionLayer : <span class="keyword">public</span> ConvolutionLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;  <span class="keyword">explicit</span> CuDNNConvolutionLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;      : ConvolutionLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;  <span class="keyword">virtual</span> ~CuDNNConvolutionLayer();</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;  cudnnHandle_t* handle_;</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;  cudaStream_t*  stream_;</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;  vector&lt;cudnnTensorDescriptor_t&gt; bottom_descs_, top_descs_;</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;  cudnnTensorDescriptor_t    bias_desc_;</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;  cudnnFilterDescriptor_t      filter_desc_;</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;  vector&lt;cudnnConvolutionDescriptor_t&gt; conv_descs_;</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;  <span class="keywordtype">int</span> bottom_offset_, top_offset_, weight_offset_, bias_offset_;</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;  <span class="keywordtype">size_t</span> workspaceSizeInBytes;</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;  <span class="keywordtype">void</span> *workspace;</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;};</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00267"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html">  267</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1Im2colLayer.html">Im2colLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1Im2colLayer.html">Im2colLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a73d7e780b38406dc3d840649cadf8f8a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a79735ab9fb43a53e4ca02e33a0b3f181">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;</div>
<div class="line"><a name="l00276"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">  276</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Im2col&quot;</span>; }</div>
<div class="line"><a name="l00277"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">  277</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00278"></a><span class="lineno"><a class="line" href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">  278</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#ad8c319e6628c7c523c2c6a991f9c631a">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a1481790fce4361eefab8d78bbdd6f0ec">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a3b2dc21acbbe2e174cc83554469c29f5">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1Im2colLayer.html#a5340f5b2e176beeb6c74428f05e06c7c">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;  <span class="keywordtype">int</span> stride_h_, stride_w_;</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;  <span class="keywordtype">int</span> height_, width_;</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;};</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">// Forward declare PoolingLayer and SplitLayer for use in LRNLayer.</span></div>
<div class="line"><a name="l00298"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html">  298</a></span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1PoolingLayer.html">PoolingLayer</a>;</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt; <span class="keyword">class </span><a class="code" href="classcaffe_1_1SplitLayer.html">SplitLayer</a>;</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00307"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html">  307</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1LRNLayer.html">LRNLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1LRNLayer.html">LRNLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a7ab94b55392ad0500115d4a4d64b0a7c">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#ae7ca62b2339f0691dadde24fd8acb481">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;</div>
<div class="line"><a name="l00316"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">  316</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;LRN&quot;</span>; }</div>
<div class="line"><a name="l00317"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">  317</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00318"></a><span class="lineno"><a class="line" href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">  318</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">ExactNumTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#ad3ae42eb16a0f55745211a44c806e316">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a7d8e7e7e1daf4ae1205e0bfe9fb9ac51">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a71ff30a634527e2bf89c067d3c325979">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1LRNLayer.html#a1ba7e8a8af945fba73da4a0c307fc4a0">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelForward_cpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelForward_gpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> WithinChannelForward(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelBackward_cpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> CrossChannelBackward_gpu(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> WithinChannelBackward(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;  <span class="keywordtype">int</span> size_;</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;  <span class="keywordtype">int</span> pre_pad_;</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;  Dtype alpha_;</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;  Dtype beta_;</div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;  Dtype k_;</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;  <span class="keywordtype">int</span> num_;</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;  <span class="keywordtype">int</span> height_;</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;  <span class="keywordtype">int</span> width_;</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;  <span class="comment">// Fields used for normalization ACROSS_CHANNELS</span></div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;  <span class="comment">// scale_ stores the intermediate summing results</span></div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> scale_;</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;  <span class="comment">// Fields used for normalization WITHIN_CHANNEL</span></div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;  shared_ptr&lt;SplitLayer&lt;Dtype&gt; &gt; split_layer_;</div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; split_top_vec_;</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;  shared_ptr&lt;PowerLayer&lt;Dtype&gt; &gt; square_layer_;</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> square_input_;</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> square_output_;</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; square_bottom_vec_;</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; square_top_vec_;</div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;  shared_ptr&lt;PoolingLayer&lt;Dtype&gt; &gt; pool_layer_;</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> pool_output_;</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; pool_top_vec_;</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;  shared_ptr&lt;PowerLayer&lt;Dtype&gt; &gt; power_layer_;</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> power_output_;</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; power_top_vec_;</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;  shared_ptr&lt;EltwiseLayer&lt;Dtype&gt; &gt; product_layer_;</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> product_input_;</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; product_bottom_vec_;</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;};</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;</div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;<span class="keyword">class </span>PoolingLayer : <span class="keyword">public</span> Layer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;  <span class="keyword">explicit</span> PoolingLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a>&lt;Dtype&gt;(param) {}</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a5e1a46c850fcd18934309824208b31ff">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a79a285029778124aca1c803d6cfec55f">Reshape</a>(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;</div>
<div class="line"><a name="l00392"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">  392</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;Pooling&quot;</span>; }</div>
<div class="line"><a name="l00393"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">  393</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00394"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">  394</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;  <span class="comment">// MAX POOL layers can output an extra top blob for the mask;</span></div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;  <span class="comment">// others can only output the pooled inputs.</span></div>
<div class="line"><a name="l00397"></a><span class="lineno"><a class="line" href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">  397</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">MaxTopBlobs</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    <span class="keywordflow">return</span> (this-&gt;<a class="code" href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a>.pooling_param().pool() ==</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;            PoolingParameter_PoolMethod_MAX) ? 2 : 1;</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;  }</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#ac84e5fb89223f6cc2577cea2c55cd388">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a027fcd5f61e6386819e8d02815f72e4a">Forward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#a8d3cf138cdbd059a0bab72361f0860b5">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1PoolingLayer.html#ad13b67ea00c891ce922604ab66eeeb0d">Backward_gpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;  <span class="keywordtype">int</span> stride_h_, stride_w_;</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;  <span class="keywordtype">int</span> height_, width_;</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;  <span class="keywordtype">int</span> pooled_height_, pooled_width_;</div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;  <span class="keywordtype">bool</span> global_pooling_;</div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a> rand_idx_;</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;  <a class="code" href="classcaffe_1_1Blob.html">Blob&lt;int&gt;</a> max_idx_;</div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;};</div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="preprocessor">#ifdef USE_CUDNN</span></div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment"> * @brief cuDNN implementation of PoolingLayer.</span></div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment"> *        Fallback to PoolingLayer for CPU mode.</span></div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;<span class="comment">*/</span></div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="keyword">class </span>CuDNNPoolingLayer : <span class="keyword">public</span> PoolingLayer&lt;Dtype&gt; {</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <span class="keyword">explicit</span> CuDNNPoolingLayer(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;      : PoolingLayer&lt;Dtype&gt;(param), handles_setup_(false) {}</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> LayerSetUp(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Reshape(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;  <span class="keyword">virtual</span> ~CuDNNPoolingLayer();</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  <span class="comment">// Currently, cuDNN does not support the extra top blob.</span></div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> MinTopBlobs()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> -1; }</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> ExactNumTopBlobs()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Forward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;      <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> Backward_gpu(<span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom);</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;  <span class="keywordtype">bool</span> handles_setup_;</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  cudnnHandle_t             handle_;</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;  cudnnTensorDescriptor_t bottom_desc_, top_desc_;</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;  cudnnPoolingDescriptor_t  pooling_desc_;</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;  cudnnPoolingMode_t        mode_;</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;};</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div>
<div class="line"><a name="l00463"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html">  463</a></span>&#160;<span class="keyword">class </span><a class="code" href="classcaffe_1_1SPPLayer.html">SPPLayer</a> : <span class="keyword">public</span> <a class="code" href="classcaffe_1_1Layer.html">Layer</a>&lt;Dtype&gt; {</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;  <span class="keyword">explicit</span> <a class="code" href="classcaffe_1_1SPPLayer.html">SPPLayer</a>(<span class="keyword">const</span> LayerParameter&amp; param)</div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;      : <a class="code" href="classcaffe_1_1Layer.html">Layer&lt;Dtype&gt;</a>(param) {}</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#acf2c8649f50afd4a31b32cefb06de09a">LayerSetUp</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a9f54a92de230cde55b0dd4e996b9975e">Reshape</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;</div>
<div class="line"><a name="l00472"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">  472</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keyword">const</span> <span class="keywordtype">char</span>* <a class="code" href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">type</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;SPP&quot;</span>; }</div>
<div class="line"><a name="l00473"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">  473</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">ExactNumBottomBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00474"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a55618edd8bd33f910dd326d407e1cd5c">  474</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a55618edd8bd33f910dd326d407e1cd5c">MinTopBlobs</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> 1; }</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;  <span class="comment">// MAX POOL layers can output an extra top blob for the mask;</span></div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;  <span class="comment">// others can only output the pooled inputs.</span></div>
<div class="line"><a name="l00477"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#ab2cd26e1b95a6e8ba078bbbb8b697a68">  477</a></span>&#160;  <span class="keyword">virtual</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classcaffe_1_1SPPLayer.html#ab2cd26e1b95a6e8ba078bbbb8b697a68">MaxTopBlobs</a>()<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;    <span class="keywordflow">return</span> (this-&gt;<a class="code" href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a>.pooling_param().pool() ==</div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;            PoolingParameter_PoolMethod_MAX) ? 2 : 1;</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;  }</div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160; <span class="keyword">protected</span>:</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#a47c6a647030121c813845c657744547c">Forward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom,</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;      <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top);</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classcaffe_1_1SPPLayer.html#abf8677b68b68fb7c3c85f347d2bacc5d">Backward_cpu</a>(<span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; top,</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;      <span class="keyword">const</span> vector&lt;bool&gt;&amp; propagate_down, <span class="keyword">const</span> vector&lt;<a class="code" href="classcaffe_1_1Blob.html">Blob&lt;Dtype&gt;</a>*&gt;&amp; bottom);</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  <span class="comment">// calculates the kernel and stride dimensions for the pooling layer,</span></div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;  <span class="comment">// returns a correctly configured LayerParameter for a PoolingLayer</span></div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;  <span class="keyword">virtual</span> LayerParameter GetPoolingParam(<span class="keyword">const</span> <span class="keywordtype">int</span> pyramid_level,</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;      <span class="keyword">const</span> <span class="keywordtype">int</span> bottom_h, <span class="keyword">const</span> <span class="keywordtype">int</span> bottom_w, <span class="keyword">const</span> SPPParameter spp_param);</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;  <span class="keywordtype">int</span> pyramid_height_;</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;  <span class="keywordtype">int</span> bottom_h_, bottom_w_;</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;  <span class="keywordtype">int</span> channels_;</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;  <span class="keywordtype">int</span> kernel_h_, kernel_w_;</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;  <span class="keywordtype">int</span> pad_h_, pad_w_;</div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;</div>
<div class="line"><a name="l00499"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">  499</a></span>&#160;  shared_ptr&lt;SplitLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">split_layer_</a>;</div>
<div class="line"><a name="l00501"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">  501</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">split_top_vec_</a>;</div>
<div class="line"><a name="l00503"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">  503</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">pooling_bottom_vecs_</a>;</div>
<div class="line"><a name="l00505"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">  505</a></span>&#160;  vector&lt;shared_ptr&lt;PoolingLayer&lt;Dtype&gt; &gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">pooling_layers_</a>;</div>
<div class="line"><a name="l00507"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">  507</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">pooling_top_vecs_</a>;</div>
<div class="line"><a name="l00509"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">  509</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">pooling_outputs_</a>;</div>
<div class="line"><a name="l00511"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">  511</a></span>&#160;  vector&lt;FlattenLayer&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">flatten_layers_</a>;</div>
<div class="line"><a name="l00513"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">  513</a></span>&#160;  vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">flatten_top_vecs_</a>;</div>
<div class="line"><a name="l00515"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">  515</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">flatten_outputs_</a>;</div>
<div class="line"><a name="l00517"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">  517</a></span>&#160;  vector&lt;Blob&lt;Dtype&gt;*&gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">concat_bottom_vec_</a>;</div>
<div class="line"><a name="l00519"></a><span class="lineno"><a class="line" href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">  519</a></span>&#160;  shared_ptr&lt;ConcatLayer&lt;Dtype&gt; &gt; <a class="code" href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">concat_layer_</a>;</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;};</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;}  <span class="comment">// namespace caffe</span></div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;<span class="preprocessor">#endif  // CAFFE_VISION_LAYERS_HPP_</span></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a7ab94b55392ad0500115d4a4d64b0a7c"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a7ab94b55392ad0500115d4a4d64b0a7c">caffe::LRNLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:10</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html">caffe::Im2colLayer</a></div><div class="ttdoc">A helper for image operations that rearranges image regions into column vectors. Used by ConvolutionL...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:267</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_ad13b67ea00c891ce922604ab66eeeb0d"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#ad13b67ea00c891ce922604ab66eeeb0d">caffe::PoolingLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_aab9056708727154a01866d17756c07cc"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#aab9056708727154a01866d17756c07cc">caffe::LRNLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:318</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html"><div class="ttname"><a href="classcaffe_1_1Layer.html">caffe::Layer</a></div><div class="ttdoc">An interface for the units of computation which can be composed into a Net. </div><div class="ttdef"><b>Definition:</b> layer.hpp:27</div></div>
<div class="ttc" id="namespacecaffe_html"><div class="ttname"><a href="namespacecaffe.html">caffe</a></div><div class="ttdoc">A layer factory that allows one to register layers. During runtime, registered layers could be called...</div><div class="ttdef"><b>Definition:</b> blob.hpp:15</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_afdcf33e7ec63ca5e476ffdc1da1f1fa0"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#afdcf33e7ec63ca5e476ffdc1da1f1fa0">caffe::ConvolutionLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:164</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a027fcd5f61e6386819e8d02815f72e4a"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a027fcd5f61e6386819e8d02815f72e4a">caffe::PoolingLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a7d8e7e7e1daf4ae1205e0bfe9fb9ac51"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a7d8e7e7e1daf4ae1205e0bfe9fb9ac51">caffe::LRNLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_add4567680b9466cbae5804da6a76e2ee"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#add4567680b9466cbae5804da6a76e2ee">caffe::BaseConvolutionLayer::EqualNumBottomTopBlobs</a></div><div class="ttdeci">virtual bool EqualNumBottomTopBlobs() const </div><div class="ttdoc">Returns true if the layer requires an equal number of bottom and top blobs. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:35</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a79735ab9fb43a53e4ca02e33a0b3f181"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a79735ab9fb43a53e4ca02e33a0b3f181">caffe::Im2colLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:51</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a6fc8f79729e17639d3b97781791e352d"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a6fc8f79729e17639d3b97781791e352d">caffe::PoolingLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:393</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a4cde4ff418007bcbdd34f91c6abbea1f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a4cde4ff418007bcbdd34f91c6abbea1f">caffe::SPPLayer::pooling_layers_</a></div><div class="ttdeci">vector&lt; shared_ptr&lt; PoolingLayer&lt; Dtype &gt; &gt; &gt; pooling_layers_</div><div class="ttdoc">the internal Pooling layers of different kernel sizes </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:505</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a2a79eac8d3e85873c1fede0f1e8f0a45"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a2a79eac8d3e85873c1fede0f1e8f0a45">caffe::PoolingLayer::MaxTopBlobs</a></div><div class="ttdeci">virtual int MaxTopBlobs() const </div><div class="ttdoc">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:397</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ac1591049f064bd88ccdc785a948ed4b2"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ac1591049f064bd88ccdc785a948ed4b2">caffe::ConvolutionLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> conv_layer.cpp:38</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_acf2c8649f50afd4a31b32cefb06de09a"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#acf2c8649f50afd4a31b32cefb06de09a">caffe::SPPLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:65</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a7460ba8ed098335de91cd8cab363d365"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a7460ba8ed098335de91cd8cab363d365">caffe::SPPLayer::flatten_top_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; flatten_top_vecs_</div><div class="ttdoc">top vector holders used in call to the underlying FlattenLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:513</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a4bddcb27cbc0e9e2d153d134d5f9d760"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a4bddcb27cbc0e9e2d153d134d5f9d760">caffe::SPPLayer::pooling_top_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; pooling_top_vecs_</div><div class="ttdoc">top vector holders used in call to the underlying PoolingLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:507</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_aabbbcdeb646c188ac2137b003aa1c682"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#aabbbcdeb646c188ac2137b003aa1c682">caffe::LRNLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:317</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_aa4c2a009d84367e72b98b3b8542e3a0f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#aa4c2a009d84367e72b98b3b8542e3a0f">caffe::SPPLayer::split_top_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; split_top_vec_</div><div class="ttdoc">top vector holder used in call to the underlying SplitLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:501</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a3716cda5f7d7e81f7d19cf4313d2bfc5"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a3716cda5f7d7e81f7d19cf4313d2bfc5">caffe::DeconvolutionLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> deconv_layer.cpp:20</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_ab6912cfa8daa151407d024d5113e10b0"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#ab6912cfa8daa151407d024d5113e10b0">caffe::SPPLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:473</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a14a2760d3eafcfce766222f80e126fbe"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a14a2760d3eafcfce766222f80e126fbe">caffe::BaseConvolutionLayer::MinBottomBlobs</a></div><div class="ttdeci">virtual int MinBottomBlobs() const </div><div class="ttdoc">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is requi...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:33</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html">caffe::SPPLayer</a></div><div class="ttdoc">Does spatial pyramid pooling on the input image by taking the max, average, etc. within regions so th...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:463</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a1481790fce4361eefab8d78bbdd6f0ec"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a1481790fce4361eefab8d78bbdd6f0ec">caffe::Im2colLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a0b4899ba1d3fe6f041dd5cc88a380c44"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a0b4899ba1d3fe6f041dd5cc88a380c44">caffe::PoolingLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:392</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a5340f5b2e176beeb6c74428f05e06c7c"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a5340f5b2e176beeb6c74428f05e06c7c">caffe::Im2colLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aac44aaa893e6fb774c1953b523180cea"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aac44aaa893e6fb774c1953b523180cea">caffe::Im2colLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:276</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a47c6a647030121c813845c657744547c"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a47c6a647030121c813845c657744547c">caffe::SPPLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:160</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a7498a14d8b7afa0bc85abe1dbd719135"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a7498a14d8b7afa0bc85abe1dbd719135">caffe::DeconvolutionLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:199</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a71054cf06805c96615332b70fdb45a8b"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a71054cf06805c96615332b70fdb45a8b">caffe::SPPLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:472</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_ac330e2fb166bca496edd277b0495f6eb"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#ac330e2fb166bca496edd277b0495f6eb">caffe::BaseConvolutionLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> base_conv_layer.cpp:104</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_abc72dca274a4ab42f7a12de4d1e8f8eb"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#abc72dca274a4ab42f7a12de4d1e8f8eb">caffe::PoolingLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:394</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_a4de7682afbd816037aba5da3ec66a9bb"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#a4de7682afbd816037aba5da3ec66a9bb">caffe::ConvolutionLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html">caffe::BaseConvolutionLayer</a></div><div class="ttdoc">Abstract base class that factors out the BLAS code common to ConvolutionLayer and DeconvolutionLayer...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:24</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_ab2cd26e1b95a6e8ba078bbbb8b697a68"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#ab2cd26e1b95a6e8ba078bbbb8b697a68">caffe::SPPLayer::MaxTopBlobs</a></div><div class="ttdeci">virtual int MaxTopBlobs() const </div><div class="ttdoc">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:477</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a71ff30a634527e2bf89c067d3c325979"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a71ff30a634527e2bf89c067d3c325979">caffe::LRNLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:166</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a73d7e780b38406dc3d840649cadf8f8a"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a73d7e780b38406dc3d840649cadf8f8a">caffe::Im2colLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:11</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a2c9e8e5e918431ccc43e8578419357c9"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a2c9e8e5e918431ccc43e8578419357c9">caffe::SPPLayer::pooling_bottom_vecs_</a></div><div class="ttdeci">vector&lt; vector&lt; Blob&lt; Dtype &gt; * &gt; * &gt; pooling_bottom_vecs_</div><div class="ttdoc">bottom vector holder used in call to the underlying PoolingLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:503</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a2874ca5b0c4d8f7d970c5a30768d2bc0"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a2874ca5b0c4d8f7d970c5a30768d2bc0">caffe::SPPLayer::concat_bottom_vec_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; concat_bottom_vec_</div><div class="ttdoc">bottom vector holder used in call to the underlying ConcatLayer::Forward </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:517</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a79a285029778124aca1c803d6cfec55f"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a79a285029778124aca1c803d6cfec55f">caffe::PoolingLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:82</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_a35c6389878e77ab0a4a479e5441563cc"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#a35c6389878e77ab0a4a479e5441563cc">caffe::BaseConvolutionLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> base_conv_layer.cpp:12</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_a8505044adc26d89aae3055022898c9ea"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#a8505044adc26d89aae3055022898c9ea">caffe::ConvolutionLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> conv_layer.cpp:20</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ace239a41953c9207efd1a9966570825c"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ace239a41953c9207efd1a9966570825c">caffe::ConvolutionLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a765c32194d96177869e2b9028b1ff0d4"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a765c32194d96177869e2b9028b1ff0d4">caffe::SPPLayer::flatten_layers_</a></div><div class="ttdeci">vector&lt; FlattenLayer&lt; Dtype &gt; * &gt; flatten_layers_</div><div class="ttdoc">the internal Flatten layers that the Pooling layers feed into </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:511</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a5e1a46c850fcd18934309824208b31ff"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a5e1a46c850fcd18934309824208b31ff">caffe::PoolingLayer::LayerSetUp</a></div><div class="ttdeci">virtual void LayerSetUp(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Does layer-specific setup: your layer should implement this function as well as Reshape. </div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:17</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a55618edd8bd33f910dd326d407e1cd5c"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a55618edd8bd33f910dd326d407e1cd5c">caffe::SPPLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:474</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_ae7ca62b2339f0691dadde24fd8acb481"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#ae7ca62b2339f0691dadde24fd8acb481">caffe::LRNLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:70</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_a3b2dc21acbbe2e174cc83554469c29f5"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#a3b2dc21acbbe2e174cc83554469c29f5">caffe::Im2colLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:77</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html_a7b4e4ccea08c7b8b15acc6829d5735f6"><div class="ttname"><a href="classcaffe_1_1Layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">caffe::Layer::Layer</a></div><div class="ttdeci">Layer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> layer.hpp:34</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_afd42f96c91f26fe32427865a16796503"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#afd42f96c91f26fe32427865a16796503">caffe::SPPLayer::flatten_outputs_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; flatten_outputs_</div><div class="ttdoc">flatten_outputs stores the outputs of the FlattenLayers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:515</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a28dbd28c7542ae178973f0cb7b73cf8a"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a28dbd28c7542ae178973f0cb7b73cf8a">caffe::LRNLayer::type</a></div><div class="ttdeci">virtual const char * type() const </div><div class="ttdoc">Returns the layer type. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:316</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a9f54a92de230cde55b0dd4e996b9975e"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a9f54a92de230cde55b0dd4e996b9975e">caffe::SPPLayer::Reshape</a></div><div class="ttdeci">virtual void Reshape(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Adjust the shapes of top blobs and internal buffers to accomodate the shapes of the bottom blobs...</div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:134</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aba3720be3f1f71f9e44fbfba90ae3ac0"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aba3720be3f1f71f9e44fbfba90ae3ac0">caffe::Im2colLayer::ExactNumBottomBlobs</a></div><div class="ttdeci">virtual int ExactNumBottomBlobs() const </div><div class="ttdoc">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:277</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_a1ba7e8a8af945fba73da4a0c307fc4a0"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#a1ba7e8a8af945fba73da4a0c307fc4a0">caffe::LRNLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html_ad27360afd7729001b9e4f1d8c8401866"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html#ad27360afd7729001b9e4f1d8c8401866">caffe::ConvolutionLayer::ConvolutionLayer</a></div><div class="ttdeci">ConvolutionLayer(const LayerParameter &amp;param)</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:161</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html">caffe::DeconvolutionLayer</a></div><div class="ttdoc">Convolve the input with a bank of learned filters, and (optionally) add biases, treating filters and ...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:194</div></div>
<div class="ttc" id="classcaffe_1_1Layer_html_a7ed12bb2df25c887e41d7ea9557fc701"><div class="ttname"><a href="classcaffe_1_1Layer.html#a7ed12bb2df25c887e41d7ea9557fc701">caffe::Layer::layer_param_</a></div><div class="ttdeci">LayerParameter layer_param_</div><div class="ttdef"><b>Definition:</b> layer.hpp:291</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html">caffe::PoolingLayer</a></div><div class="ttdoc">Pools the input image by taking the max, average, etc. within regions. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:298</div></div>
<div class="ttc" id="classcaffe_1_1SplitLayer_html"><div class="ttname"><a href="classcaffe_1_1SplitLayer.html">caffe::SplitLayer</a></div><div class="ttdoc">Creates a "split" path in the network by copying the bottom Blob into multiple top Blobs to be used b...</div><div class="ttdef"><b>Definition:</b> common_layers.hpp:440</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a49c3360133291f7e6593db36ec392d07"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a49c3360133291f7e6593db36ec392d07">caffe::DeconvolutionLayer::Forward_gpu</a></div><div class="ttdeci">virtual void Forward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the GPU device, compute the layer output. Fall back to Forward_cpu() if unavailable. </div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a2b4a2203001e8b5a5839955879551048"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a2b4a2203001e8b5a5839955879551048">caffe::DeconvolutionLayer::Backward_gpu</a></div><div class="ttdeci">virtual void Backward_gpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a02a9d50a48983fa0c6e42cafa85c1eb8"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a02a9d50a48983fa0c6e42cafa85c1eb8">caffe::SPPLayer::concat_layer_</a></div><div class="ttdeci">shared_ptr&lt; ConcatLayer&lt; Dtype &gt; &gt; concat_layer_</div><div class="ttdoc">the internal Concat layers that the Flatten layers feed into </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:519</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_abf8677b68b68fb7c3c85f347d2bacc5d"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#abf8677b68b68fb7c3c85f347d2bacc5d">caffe::SPPLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> spp_layer.cpp:173</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_ad8c319e6628c7c523c2c6a991f9c631a"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#ad8c319e6628c7c523c2c6a991f9c631a">caffe::Im2colLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> im2col_layer.cpp:65</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_a9312cb2eb190ce25d9269d9319cf5e4b"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#a9312cb2eb190ce25d9269d9319cf5e4b">caffe::SPPLayer::split_layer_</a></div><div class="ttdeci">shared_ptr&lt; SplitLayer&lt; Dtype &gt; &gt; split_layer_</div><div class="ttdoc">the internal Split layer that feeds the pooling layers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:499</div></div>
<div class="ttc" id="classcaffe_1_1ConvolutionLayer_html"><div class="ttname"><a href="classcaffe_1_1ConvolutionLayer.html">caffe::ConvolutionLayer</a></div><div class="ttdoc">Convolves the input image with a bank of learned filters, and (optionally) adds biases. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:131</div></div>
<div class="ttc" id="classcaffe_1_1DeconvolutionLayer_html_a081ed64d7b91d42f9f441f849db2a58d"><div class="ttname"><a href="classcaffe_1_1DeconvolutionLayer.html#a081ed64d7b91d42f9f441f849db2a58d">caffe::DeconvolutionLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> deconv_layer.cpp:38</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_a8d3cf138cdbd059a0bab72361f0860b5"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#a8d3cf138cdbd059a0bab72361f0860b5">caffe::PoolingLayer::Backward_cpu</a></div><div class="ttdeci">virtual void Backward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom)</div><div class="ttdoc">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...</div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:233</div></div>
<div class="ttc" id="classcaffe_1_1PoolingLayer_html_ac84e5fb89223f6cc2577cea2c55cd388"><div class="ttname"><a href="classcaffe_1_1PoolingLayer.html#ac84e5fb89223f6cc2577cea2c55cd388">caffe::PoolingLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> pooling_layer.cpp:131</div></div>
<div class="ttc" id="classcaffe_1_1Im2colLayer_html_aa4aa1cfc956fa1ab3656ad2adf911f32"><div class="ttname"><a href="classcaffe_1_1Im2colLayer.html#aa4aa1cfc956fa1ab3656ad2adf911f32">caffe::Im2colLayer::ExactNumTopBlobs</a></div><div class="ttdeci">virtual int ExactNumTopBlobs() const </div><div class="ttdoc">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:278</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html">caffe::LRNLayer</a></div><div class="ttdoc">Normalize the input in a local region across or within feature maps. </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:307</div></div>
<div class="ttc" id="classcaffe_1_1SPPLayer_html_aed09b8f30c285651c726ac7ca186f93f"><div class="ttname"><a href="classcaffe_1_1SPPLayer.html#aed09b8f30c285651c726ac7ca186f93f">caffe::SPPLayer::pooling_outputs_</a></div><div class="ttdeci">vector&lt; Blob&lt; Dtype &gt; * &gt; pooling_outputs_</div><div class="ttdoc">pooling_outputs stores the outputs of the PoolingLayers </div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:509</div></div>
<div class="ttc" id="classcaffe_1_1Blob_html"><div class="ttname"><a href="classcaffe_1_1Blob.html">caffe::Blob</a></div><div class="ttdoc">A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...</div><div class="ttdef"><b>Definition:</b> blob.hpp:25</div></div>
<div class="ttc" id="classcaffe_1_1BaseConvolutionLayer_html_accd0683191124da91a3667acc57e5ecd"><div class="ttname"><a href="classcaffe_1_1BaseConvolutionLayer.html#accd0683191124da91a3667acc57e5ecd">caffe::BaseConvolutionLayer::MinTopBlobs</a></div><div class="ttdeci">virtual int MinTopBlobs() const </div><div class="ttdoc">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...</div><div class="ttdef"><b>Definition:</b> vision_layers.hpp:34</div></div>
<div class="ttc" id="classcaffe_1_1LRNLayer_html_ad3ae42eb16a0f55745211a44c806e316"><div class="ttname"><a href="classcaffe_1_1LRNLayer.html#ad3ae42eb16a0f55745211a44c806e316">caffe::LRNLayer::Forward_cpu</a></div><div class="ttdeci">virtual void Forward_cpu(const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;bottom, const vector&lt; Blob&lt; Dtype &gt; * &gt; &amp;top)</div><div class="ttdoc">Using the CPU device, compute the layer output. </div><div class="ttdef"><b>Definition:</b> lrn_layer.cpp:94</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri May 29 2015 12:07:28 for Caffe by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.9.1
</small></address>
</body>
</html>
